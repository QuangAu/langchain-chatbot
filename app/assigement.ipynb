{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple chatbot\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Run this command to create virtual envrionment: `virtualenv langchain --python=python3.11`\n",
    "2. Activate the environment: `source langchain/bin/activate`\n",
    "3. Import required packages: `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "\n",
    "1. Import package and init base objects: AzureOpenAIEmbeddings and ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import settings\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "# Init base objects\n",
    "azure_embedding = AzureOpenAIEmbeddings(\n",
    "    model=settings.AZURE_OPENAI_API_EMBEDDING_MODEL,\n",
    "    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=settings.AZURE_OPENAI_API_KEY,\n",
    "    openai_api_version=settings.AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    embedding_function=azure_embedding,\n",
    "    persist_directory=\"../langchain.db\",\n",
    "    collection_name=\"langchain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load data from pdf file into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_documents = data_loader.load_pdf_file()\n",
    "enhanced_documents = data_loader.process_documents(original_documents)\n",
    "vectordb.add_documents(enhanced_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set up agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=settings.AZURE_OPENAI_API_CHAT_MODEL,\n",
    "    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "    model=settings.AZURE_OPENAI_API_CHAT_MODEL,\n",
    "    api_version=settings.AZURE_OPENAI_API_VERSION,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def internal_knowledge_search(query):\n",
    "    \"\"\"Search internal knowledge using vector\"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    return results\n",
    "\n",
    "\n",
    "tools = [\n",
    "            Tool(\n",
    "                    name=\"InternalKnownledge\",\n",
    "                    func=internal_knowledge_search,\n",
    "                    description=\"Use this tool to search internal knowledge at Nashtech\"\n",
    "                ),\n",
    "            DuckDuckGoSearchRun(description=\"Use this tool to search information on the Internet\")\n",
    "        ]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an intelligent assistant with access to multiple tools. \\\n",
    "            Always search InternalKnownledge. \\\n",
    "                Make sure the page_number and source are included in the response\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=5)\n",
    "agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Start the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "while (True):\n",
    "    question = input(\"You: \")\n",
    "    if question == \"quit\":\n",
    "        break\n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    print(f'AI: {result[\"output\"]}')\n",
    "    print(\"====================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
